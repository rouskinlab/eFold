{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from efold import DataModule, create_model, Dataset\n",
    "from efold.config import device\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch import Trainer\n",
    "from efold.config import device\n",
    "import sys\n",
    "import os\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import torch, wandb\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk\n",
      "Done!                            \n",
      "Loading dataset from disk\n",
      "Done!                            \n",
      "Loading dataset from disk\n",
      "Done!                            \n",
      "Loading dataset from disk\n",
      "Done!                            \n"
     ]
    }
   ],
   "source": [
    "dm = DataModule(\n",
    "    name=[\"RNAstralign\", \"archiveII\", \"ribo500-blast\", 'bpRNA'],\n",
    "    data_type=['structure'],\n",
    "    force_download=False,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    predict_split=0,\n",
    "    shuffle_valid=False,\n",
    "    structure_padding_value=0,\n",
    "    min_len=100,\n",
    "    max_len=500,\n",
    ")\n",
    "dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122, 108, 119, 123, 122, 124, 118, 122, 118, 105, 107, 116, 118, 120, 115, 120, 117, 117, 103, 118, 115, 121, 135, 120, 136, 127, 115, 140, 148, 104, 115, 102, 126, 108, 117, 118, 122, 115, 117, 115, 115, 117, 125, 114, 123, 122, 121, 118, 105, 140, 119, 118, 120, 116, 113, 147, 121, 130, 120, 113, 119, 142, 123, 140]\n"
     ]
    }
   ],
   "source": [
    "for batch in dm.train_dataloader():\n",
    "    print(batch.get('length'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "names = [\"RNAstralign\", \"archiveII\", \"ribo500-blast\", 'bpRNA']\n",
    "data = {}\n",
    "for name in names:\n",
    "    with open(f'./data/{name}/data.json', 'r') as f:\n",
    "        temp = json.load(f)\n",
    "        data.update(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1903 [00:00<18:36,  1.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 27/1903 [00:20<26:11,  1.19it/s]"
     ]
    }
   ],
   "source": [
    "from efold.core.util import _pad, base_pairs_to_pairing_matrix\n",
    "import tqdm \n",
    "\n",
    "def compare_data(dt, data_line, from_ds, ref):\n",
    "    from_ds = from_ds.cpu().numpy().round(4)\n",
    "    \n",
    "    if not dt in data_line:\n",
    "        assert from_ds is None or set(from_ds) == set([-1000.]), f'{dt} is None in the json and not not in the datamodule for {ref}: {from_ds}'\n",
    "        return\n",
    "    L = len(data_line['sequence'])\n",
    "    data_line = np.array(data_line[dt])\n",
    "    \n",
    "    if dt == 'structure':\n",
    "        data_line = base_pairs_to_pairing_matrix(data_line, L, padding=len(from_ds), pad_value=0).numpy().round(4)\n",
    "\n",
    "    else:\n",
    "        from_ds = np.array(from_ds)[:L].round(4)\n",
    "        data_line = data_line.round(4)\n",
    "    \n",
    "    if not np.allclose(data_line, from_ds, atol=1e-6):\n",
    "        assert 0, f'{dt} keys do not match for {ref}: \\ndata_line:\\t{data_line.tolist()} \\nfrom_ds:\\t{from_ds.tolist()}'\n",
    "    return\n",
    "\n",
    "def sanity_check(data:dict, dm:DataModule):\n",
    "    for batch in tqdm.tqdm(dm.train_dataloader(), total=len(dm.train_dataloader())):\n",
    "        for ref, dms, shape, structure in zip(batch.get('reference'), batch.get('dms'), batch.get('shape'), batch.get('structure')):\n",
    "            for dt, from_ds in zip(['dms', 'shape', 'structure'], [dms, shape, structure]):\n",
    "                compare_data(dt, data[ref], from_ds, ref)\n",
    "\n",
    "sanity_check(data, dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
